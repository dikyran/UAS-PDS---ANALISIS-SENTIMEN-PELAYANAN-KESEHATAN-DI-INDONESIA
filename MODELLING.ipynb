{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d6b62b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from keras.preprocessing import sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import re\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, precision_score, recall_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "nb = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e5f3d377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>polarity_score</th>\n",
       "      <th>polarity</th>\n",
       "      <th>stemming_ulasan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>['pemerintah', 'hapus', 'kelas', 'dulunya', 'k...</td>\n",
       "      <td>-24</td>\n",
       "      <td>negatif</td>\n",
       "      <td>perintah hapus kelas dulunya kelas sama standa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>['rancangan', 'asuransi', 'meringankan', 'perk...</td>\n",
       "      <td>-6</td>\n",
       "      <td>negatif</td>\n",
       "      <td>rancang asuransi ringan kembang berat masyarak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>['bikin', 'perpanjang', 'berlaku', 'menyertaka...</td>\n",
       "      <td>-11</td>\n",
       "      <td>negatif</td>\n",
       "      <td>bikin panjang laku serta bpjs sehat aktif polri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>['konsep', 'gotong', 'royong', 'berkeadilan', ...</td>\n",
       "      <td>0</td>\n",
       "      <td>positif</td>\n",
       "      <td>konsep gotong royong adil jadi butuh politis b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>['password', 'social', 'media']</td>\n",
       "      <td>0</td>\n",
       "      <td>positif</td>\n",
       "      <td>password social media</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1352</th>\n",
       "      <td>1352</td>\n",
       "      <td>['layangan', 'vaksin', 'internasional', 'kebut...</td>\n",
       "      <td>-4</td>\n",
       "      <td>negatif</td>\n",
       "      <td>layang vaksin internasional butuh ela pandemi ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1353</th>\n",
       "      <td>1353</td>\n",
       "      <td>['pemeriksaan', 'kenal', 'risiko']</td>\n",
       "      <td>0</td>\n",
       "      <td>positif</td>\n",
       "      <td>periksa kenal risiko</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1354</th>\n",
       "      <td>1354</td>\n",
       "      <td>['vaksin', 'covid', 'bayar', 'ratusan', 'ribu'...</td>\n",
       "      <td>-1</td>\n",
       "      <td>negatif</td>\n",
       "      <td>vaksin covid bayar ratus ribu kemenkes mumpung...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1355</th>\n",
       "      <td>1355</td>\n",
       "      <td>['keliru', 'konten', 'pemasangan', 'microchip'...</td>\n",
       "      <td>-2</td>\n",
       "      <td>negatif</td>\n",
       "      <td>keliru konten pasang microchip vaksinasi indon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1356</th>\n",
       "      <td>1356</td>\n",
       "      <td>['cacar', 'monyet', 'mengkhawatirkan', 'indone...</td>\n",
       "      <td>4</td>\n",
       "      <td>positif</td>\n",
       "      <td>cacar monyet khawatir indonesia kaltara dampak...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1357 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                               text  \\\n",
       "0              0  ['pemerintah', 'hapus', 'kelas', 'dulunya', 'k...   \n",
       "1              1  ['rancangan', 'asuransi', 'meringankan', 'perk...   \n",
       "2              2  ['bikin', 'perpanjang', 'berlaku', 'menyertaka...   \n",
       "3              3  ['konsep', 'gotong', 'royong', 'berkeadilan', ...   \n",
       "4              4                    ['password', 'social', 'media']   \n",
       "...          ...                                                ...   \n",
       "1352        1352  ['layangan', 'vaksin', 'internasional', 'kebut...   \n",
       "1353        1353                 ['pemeriksaan', 'kenal', 'risiko']   \n",
       "1354        1354  ['vaksin', 'covid', 'bayar', 'ratusan', 'ribu'...   \n",
       "1355        1355  ['keliru', 'konten', 'pemasangan', 'microchip'...   \n",
       "1356        1356  ['cacar', 'monyet', 'mengkhawatirkan', 'indone...   \n",
       "\n",
       "      polarity_score polarity  \\\n",
       "0                -24  negatif   \n",
       "1                 -6  negatif   \n",
       "2                -11  negatif   \n",
       "3                  0  positif   \n",
       "4                  0  positif   \n",
       "...              ...      ...   \n",
       "1352              -4  negatif   \n",
       "1353               0  positif   \n",
       "1354              -1  negatif   \n",
       "1355              -2  negatif   \n",
       "1356               4  positif   \n",
       "\n",
       "                                        stemming_ulasan  \n",
       "0     perintah hapus kelas dulunya kelas sama standa...  \n",
       "1     rancang asuransi ringan kembang berat masyarak...  \n",
       "2       bikin panjang laku serta bpjs sehat aktif polri  \n",
       "3     konsep gotong royong adil jadi butuh politis b...  \n",
       "4                                 password social media  \n",
       "...                                                 ...  \n",
       "1352  layang vaksin internasional butuh ela pandemi ...  \n",
       "1353                               periksa kenal risiko  \n",
       "1354  vaksin covid bayar ratus ribu kemenkes mumpung...  \n",
       "1355  keliru konten pasang microchip vaksinasi indon...  \n",
       "1356  cacar monyet khawatir indonesia kaltara dampak...  \n",
       "\n",
       "[1357 rows x 5 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = r\"C:\\Users\\DIKY\\tweets-data\\DATA BERSIH.csv\"\n",
    "df=pd.read_csv(file_path)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "abb85929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0          0\n",
       "text                0\n",
       "polarity_score      0\n",
       "polarity            0\n",
       "stemming_ulasan    33\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "adbc4bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['stemming_ulasan'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "24fb2510",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['stemming_ulasan'], df['polarity'],\n",
    "                                                    test_size = 0.30,\n",
    "                                                    random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0e95991a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['stemming_ulasan']\n",
    "y = df['polarity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "79f63459",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PEMBOBOTAN\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train)\n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "81e9cf92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 3183)\t0.22379204705752678\n",
      "  (0, 1998)\t0.16790980425654\n",
      "  (0, 1247)\t0.14101701982684367\n",
      "  (0, 913)\t0.20309829024985598\n",
      "  (0, 344)\t0.1702994617106547\n",
      "  (0, 408)\t0.08879504241910986\n",
      "  (0, 1032)\t0.17289716725635043\n",
      "  (0, 2968)\t0.44758409411505357\n",
      "  (0, 2692)\t0.1702994617106547\n",
      "  (0, 751)\t0.22379204705752678\n",
      "  (0, 1418)\t0.6935288681100086\n",
      "  (0, 1061)\t0.13588646815771158\n",
      "  (0, 2297)\t0.12225004639015728\n",
      "  (1, 3050)\t0.3362525055408212\n",
      "  (1, 3091)\t0.27463714100183817\n",
      "  (1, 1665)\t0.14679271745261258\n",
      "  (1, 3313)\t0.5079864609845872\n",
      "  (1, 2896)\t0.21841179574770303\n",
      "  (1, 1834)\t0.17289673920142698\n",
      "  (1, 1432)\t0.29607144631159954\n",
      "  (1, 2608)\t0.3226098765046901\n",
      "  (1, 201)\t0.3033816708335089\n",
      "  (1, 2524)\t0.3120278313100076\n",
      "  (1, 344)\t0.2705108361261966\n",
      "  (2, 2363)\t0.4256348598150162\n",
      "  :\t:\n",
      "  (1319, 1834)\t0.20379669498956102\n",
      "  (1320, 2293)\t0.5999366504277769\n",
      "  (1320, 2613)\t0.5999366504277769\n",
      "  (1320, 1443)\t0.5292938984600132\n",
      "  (1321, 1970)\t0.510850217046805\n",
      "  (1321, 559)\t0.2521894434908619\n",
      "  (1321, 3376)\t0.23591864639387689\n",
      "  (1321, 2601)\t0.3735355395553014\n",
      "  (1321, 2538)\t0.4163749191467417\n",
      "  (1321, 1436)\t0.2586082571647156\n",
      "  (1321, 310)\t0.3387230175298267\n",
      "  (1321, 1021)\t0.3539301438632683\n",
      "  (1322, 1889)\t0.47872748654660136\n",
      "  (1322, 1561)\t0.47872748654660136\n",
      "  (1322, 2225)\t0.4528327747340216\n",
      "  (1322, 3377)\t0.3016582776270137\n",
      "  (1322, 1421)\t0.4528327747340216\n",
      "  (1322, 1187)\t0.2013137527394099\n",
      "  (1323, 1942)\t0.43488264118735753\n",
      "  (1323, 452)\t0.43488264118735753\n",
      "  (1323, 590)\t0.41723833385816866\n",
      "  (1323, 1365)\t0.43488264118735753\n",
      "  (1323, 476)\t0.2730222298442595\n",
      "  (1323, 1487)\t0.3829156078556514\n",
      "  (1323, 1187)\t0.19333374566378464\n"
     ]
    }
   ],
   "source": [
    "# PROSES TF IDF\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tf = TfidfVectorizer()\n",
    "text_tf = tf.fit_transform(df['stemming_ulasan'].astype('U'))\n",
    "print(text_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bc24cadb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aamiin</th>\n",
       "      <th>aangeboden</th>\n",
       "      <th>aanricht</th>\n",
       "      <th>abad</th>\n",
       "      <th>abang</th>\n",
       "      <th>abdi</th>\n",
       "      <th>abdomen</th>\n",
       "      <th>abdul</th>\n",
       "      <th>about</th>\n",
       "      <th>absah</th>\n",
       "      <th>...</th>\n",
       "      <th>zijn</th>\n",
       "      <th>zionis</th>\n",
       "      <th>zm</th>\n",
       "      <th>zoals</th>\n",
       "      <th>zolang</th>\n",
       "      <th>zolim</th>\n",
       "      <th>zoon</th>\n",
       "      <th>zorg</th>\n",
       "      <th>zorgen</th>\n",
       "      <th>zoveel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1352</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1353</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1354</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1355</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1356</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1324 rows Ã— 3510 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      aamiin  aangeboden  aanricht  abad  abang  abdi  abdomen  abdul  about  \\\n",
       "0        0.0         0.0       0.0   0.0    0.0   0.0      0.0    0.0    0.0   \n",
       "1        0.0         0.0       0.0   0.0    0.0   0.0      0.0    0.0    0.0   \n",
       "2        0.0         0.0       0.0   0.0    0.0   0.0      0.0    0.0    0.0   \n",
       "3        0.0         0.0       0.0   0.0    0.0   0.0      0.0    0.0    0.0   \n",
       "4        0.0         0.0       0.0   0.0    0.0   0.0      0.0    0.0    0.0   \n",
       "...      ...         ...       ...   ...    ...   ...      ...    ...    ...   \n",
       "1352     0.0         0.0       0.0   0.0    0.0   0.0      0.0    0.0    0.0   \n",
       "1353     0.0         0.0       0.0   0.0    0.0   0.0      0.0    0.0    0.0   \n",
       "1354     0.0         0.0       0.0   0.0    0.0   0.0      0.0    0.0    0.0   \n",
       "1355     0.0         0.0       0.0   0.0    0.0   0.0      0.0    0.0    0.0   \n",
       "1356     0.0         0.0       0.0   0.0    0.0   0.0      0.0    0.0    0.0   \n",
       "\n",
       "      absah  ...  zijn  zionis   zm  zoals  zolang  zolim  zoon  zorg  zorgen  \\\n",
       "0       0.0  ...   0.0     0.0  0.0    0.0     0.0    0.0   0.0   0.0     0.0   \n",
       "1       0.0  ...   0.0     0.0  0.0    0.0     0.0    0.0   0.0   0.0     0.0   \n",
       "2       0.0  ...   0.0     0.0  0.0    0.0     0.0    0.0   0.0   0.0     0.0   \n",
       "3       0.0  ...   0.0     0.0  0.0    0.0     0.0    0.0   0.0   0.0     0.0   \n",
       "4       0.0  ...   0.0     0.0  0.0    0.0     0.0    0.0   0.0   0.0     0.0   \n",
       "...     ...  ...   ...     ...  ...    ...     ...    ...   ...   ...     ...   \n",
       "1352    0.0  ...   0.0     0.0  0.0    0.0     0.0    0.0   0.0   0.0     0.0   \n",
       "1353    0.0  ...   0.0     0.0  0.0    0.0     0.0    0.0   0.0   0.0     0.0   \n",
       "1354    0.0  ...   0.0     0.0  0.0    0.0     0.0    0.0   0.0   0.0     0.0   \n",
       "1355    0.0  ...   0.0     0.0  0.0    0.0     0.0    0.0   0.0   0.0     0.0   \n",
       "1356    0.0  ...   0.0     0.0  0.0    0.0     0.0    0.0   0.0   0.0     0.0   \n",
       "\n",
       "      zoveel  \n",
       "0        0.0  \n",
       "1        0.0  \n",
       "2        0.0  \n",
       "3        0.0  \n",
       "4        0.0  \n",
       "...      ...  \n",
       "1352     0.0  \n",
       "1353     0.0  \n",
       "1354     0.0  \n",
       "1355     0.0  \n",
       "1356     0.0  \n",
       "\n",
       "[1324 rows x 3510 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "text_tf = tfidf.fit_transform(df['stemming_ulasan'].astype('U'))\n",
    "\n",
    "# Konversi hasil TF-IDF ke dalam DataFrame\n",
    "tfidf_df = pd.DataFrame(text_tf.toarray(), columns=tfidf.get_feature_names_out(), index=df.index)\n",
    "\n",
    "# Tampilkan DataFrame sebagai tabel\n",
    "tfidf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5f40d3a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test size: 0.1\n",
      "random state: 42\n",
      "0.9538203190596137\n",
      "confusion matrix:\n",
      " [[58 16]\n",
      " [17 42]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     negatif       0.77      0.78      0.78        74\n",
      "     positif       0.72      0.71      0.72        59\n",
      "\n",
      "    accuracy                           0.75       133\n",
      "   macro avg       0.75      0.75      0.75       133\n",
      "weighted avg       0.75      0.75      0.75       133\n",
      "\n",
      "Accuracy Score: 0.75\n",
      "Recall Score: 0.7518796992481203\n",
      "Precision Score: 0.7515098090052718\n",
      "\n",
      "\n",
      "=================================================================\n",
      "test size: 0.2\n",
      "random state: 42\n",
      "0.9575070821529745\n",
      "confusion matrix:\n",
      " [[115  36]\n",
      " [ 30  84]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     negatif       0.79      0.76      0.78       151\n",
      "     positif       0.70      0.74      0.72       114\n",
      "\n",
      "    accuracy                           0.75       265\n",
      "   macro avg       0.75      0.75      0.75       265\n",
      "weighted avg       0.75      0.75      0.75       265\n",
      "\n",
      "Accuracy Score: 0.75\n",
      "Recall Score: 0.7509433962264151\n",
      "Precision Score: 0.7530513988288875\n",
      "\n",
      "\n",
      "=================================================================\n",
      "test size: 0.3\n",
      "random state: 42\n",
      "0.9632829373650108\n",
      "confusion matrix:\n",
      " [[164  58]\n",
      " [ 54 122]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     negatif       0.75      0.74      0.75       222\n",
      "     positif       0.68      0.69      0.69       176\n",
      "\n",
      "    accuracy                           0.72       398\n",
      "   macro avg       0.72      0.72      0.72       398\n",
      "weighted avg       0.72      0.72      0.72       398\n",
      "\n",
      "Accuracy Score: 0.72\n",
      "Recall Score: 0.7185929648241206\n",
      "Precision Score: 0.7193418673387324\n",
      "\n",
      "\n",
      "=================================================================\n",
      "test size: 0.4\n",
      "random state: 42\n",
      "0.9596977329974811\n",
      "confusion matrix:\n",
      " [[213  77]\n",
      " [ 81 159]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     negatif       0.72      0.73      0.73       290\n",
      "     positif       0.67      0.66      0.67       240\n",
      "\n",
      "    accuracy                           0.70       530\n",
      "   macro avg       0.70      0.70      0.70       530\n",
      "weighted avg       0.70      0.70      0.70       530\n",
      "\n",
      "Accuracy Score: 0.7\n",
      "Recall Score: 0.7018867924528301\n",
      "Precision Score: 0.7015036906991771\n",
      "\n",
      "\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "random_num = []\n",
    "matrix = []\n",
    "report = []\n",
    "acc_num = []\n",
    "re_num = []\n",
    "pre_num = []\n",
    "test_num = []\n",
    "\n",
    "for test in [0.1, 0.2, 0.3, 0.4]:\n",
    "    random = 42\n",
    "    print(\"test size:\", test)\n",
    "    print(\"random state:\", random)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test, random_state=random)\n",
    "    vectorizer = TfidfVectorizer(use_idf=True, smooth_idf=False)\n",
    "    X_train_vect = vectorizer.fit_transform(X_train)\n",
    "    X_test_vect = vectorizer.transform(X_test)\n",
    "    SVM = SVC(kernel='linear')\n",
    "    SVM.fit(X_train_vect, y_train)\n",
    "    train_score = SVM.score(X_train_vect, y_train)  # Store training score\n",
    "    print(train_score)\n",
    "    predict = SVM.predict(X_test_vect)\n",
    "    accuracy = accuracy_score(y_test, predict)\n",
    "    confusion = confusion_matrix(y_test, predict)\n",
    "    print('confusion matrix:\\n', confusion)\n",
    "    classification = classification_report(y_test, predict)  # Removed print() here\n",
    "    print(classification)  # Print the classification report directly\n",
    "    print(\"Accuracy Score:\", round(accuracy, 2))\n",
    "\n",
    "    recall = recall_score(y_test, predict, average='weighted')  # Adjusted averaging strategy here\n",
    "    print(\"Recall Score:\", recall)\n",
    "    precision = precision_score(y_test, predict, average='weighted')  # Adjusted averaging strategy here\n",
    "    print(\"Precision Score:\", precision)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    random_num.append(random)\n",
    "    matrix.append(confusion)\n",
    "    report.append(classification)  # Storing the classification report directly\n",
    "    acc_num.append(accuracy)\n",
    "    re_num.append(recall)\n",
    "    pre_num.append(precision)\n",
    "    test_num.append(test)\n",
    "    print(\"=================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b1a97095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_size</th>\n",
       "      <th>random_state</th>\n",
       "      <th>confusion_matrix</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>42</td>\n",
       "      <td>[[58, 16], [17, 42]]</td>\n",
       "      <td>0.751880</td>\n",
       "      <td>0.751880</td>\n",
       "      <td>0.751510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>42</td>\n",
       "      <td>[[115, 36], [30, 84]]</td>\n",
       "      <td>0.750943</td>\n",
       "      <td>0.750943</td>\n",
       "      <td>0.753051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3</td>\n",
       "      <td>42</td>\n",
       "      <td>[[164, 58], [54, 122]]</td>\n",
       "      <td>0.718593</td>\n",
       "      <td>0.718593</td>\n",
       "      <td>0.719342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4</td>\n",
       "      <td>42</td>\n",
       "      <td>[[213, 77], [81, 159]]</td>\n",
       "      <td>0.701887</td>\n",
       "      <td>0.701887</td>\n",
       "      <td>0.701504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_size  random_state        confusion_matrix  accuracy    recall  \\\n",
       "0        0.1            42    [[58, 16], [17, 42]]  0.751880  0.751880   \n",
       "1        0.2            42   [[115, 36], [30, 84]]  0.750943  0.750943   \n",
       "2        0.3            42  [[164, 58], [54, 122]]  0.718593  0.718593   \n",
       "3        0.4            42  [[213, 77], [81, 159]]  0.701887  0.701887   \n",
       "\n",
       "   precision  \n",
       "0   0.751510  \n",
       "1   0.753051  \n",
       "2   0.719342  \n",
       "3   0.701504  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {'test_size':test_num,\n",
    "        'random_state':random_num,\n",
    "        'confusion_matrix': matrix,\n",
    "        'accuracy': acc_num,\n",
    "        'recall': re_num,\n",
    "        'precision': pre_num}\n",
    "\n",
    "optimal = pd.DataFrame(data)\n",
    "optimal\n",
    "# optimal = optimal.sort_values(by=['accuracy','recall','precision'], ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6e620c83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_size</th>\n",
       "      <th>random_state</th>\n",
       "      <th>confusion_matrix</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>42</td>\n",
       "      <td>[[58, 16], [17, 42]]</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>42</td>\n",
       "      <td>[[115, 36], [30, 84]]</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3</td>\n",
       "      <td>42</td>\n",
       "      <td>[[164, 58], [54, 122]]</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4</td>\n",
       "      <td>42</td>\n",
       "      <td>[[213, 77], [81, 159]]</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  test_size  random_state        confusion_matrix accuracy recall precision\n",
       "0       0.1            42    [[58, 16], [17, 42]]     0.75   0.75      0.75\n",
       "1       0.2            42   [[115, 36], [30, 84]]     0.75   0.75      0.75\n",
       "2       0.3            42  [[164, 58], [54, 122]]     0.72   0.72      0.72\n",
       "3       0.4            42  [[213, 77], [81, 159]]     0.70   0.70      0.70"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal['accuracy'] = optimal['accuracy'].apply(lambda floats:format(float(floats), \".2f\"))\n",
    "optimal['recall'] = optimal['recall'].apply(lambda floats:format(float(floats), \".2f\"))\n",
    "optimal['precision'] = optimal['precision'].apply(lambda floats:format(float(floats), \".2f\"))\n",
    "optimal['test_size'] = optimal['test_size'].apply(lambda floats:format(float(floats), \".1f\"))\n",
    "optimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ef309bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@ NAIVE BAYES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "370312bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test size: 0.1\n",
      "random state: 42\n",
      "confusion matrix:\n",
      " [[61 13]\n",
      " [22 37]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     negatif       0.73      0.82      0.78        74\n",
      "     positif       0.74      0.63      0.68        59\n",
      "\n",
      "    accuracy                           0.74       133\n",
      "   macro avg       0.74      0.73      0.73       133\n",
      "weighted avg       0.74      0.74      0.73       133\n",
      "\n",
      "Accuracy Score: 0.74\n",
      "Recall Score: 0.7368421052631579\n",
      "Precision Score: 0.7371845275840203\n",
      "\n",
      "\n",
      "=================================================================\n",
      "test size: 0.2\n",
      "random state: 42\n",
      "confusion matrix:\n",
      " [[117  34]\n",
      " [ 40  74]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     negatif       0.75      0.77      0.76       151\n",
      "     positif       0.69      0.65      0.67       114\n",
      "\n",
      "    accuracy                           0.72       265\n",
      "   macro avg       0.72      0.71      0.71       265\n",
      "weighted avg       0.72      0.72      0.72       265\n",
      "\n",
      "Accuracy Score: 0.72\n",
      "Recall Score: 0.720754716981132\n",
      "Precision Score: 0.7193953718169558\n",
      "\n",
      "\n",
      "=================================================================\n",
      "test size: 0.3\n",
      "random state: 42\n",
      "confusion matrix:\n",
      " [[171  51]\n",
      " [ 64 112]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     negatif       0.73      0.77      0.75       222\n",
      "     positif       0.69      0.64      0.66       176\n",
      "\n",
      "    accuracy                           0.71       398\n",
      "   macro avg       0.71      0.70      0.70       398\n",
      "weighted avg       0.71      0.71      0.71       398\n",
      "\n",
      "Accuracy Score: 0.71\n",
      "Recall Score: 0.7110552763819096\n",
      "Precision Score: 0.7097310072093925\n",
      "\n",
      "\n",
      "=================================================================\n",
      "test size: 0.4\n",
      "random state: 42\n",
      "confusion matrix:\n",
      " [[220  70]\n",
      " [ 77 163]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     negatif       0.74      0.76      0.75       290\n",
      "     positif       0.70      0.68      0.69       240\n",
      "\n",
      "    accuracy                           0.72       530\n",
      "   macro avg       0.72      0.72      0.72       530\n",
      "weighted avg       0.72      0.72      0.72       530\n",
      "\n",
      "Accuracy Score: 0.72\n",
      "Recall Score: 0.7226415094339622\n",
      "Precision Score: 0.7220977557037158\n",
      "\n",
      "\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, recall_score, precision_score\n",
    "\n",
    "random_num = []\n",
    "matrix = []\n",
    "report = []\n",
    "acc_num = []\n",
    "re_num = []\n",
    "pre_num = []\n",
    "test_num = []\n",
    "\n",
    "for test in [0.1, 0.2, 0.3, 0.4]:\n",
    "    random = 42\n",
    "    print(\"test size:\", test)\n",
    "    print(\"random state:\", random)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test, random_state=random)\n",
    "    vectorizer = TfidfVectorizer(use_idf=True, smooth_idf=False)\n",
    "    X_train_vect = vectorizer.fit_transform(X_train)\n",
    "    X_test_vect = vectorizer.transform(X_test)\n",
    "    \n",
    "    # Menggunakan algoritma Naive Bayes\n",
    "    naive_bayes_model = MultinomialNB()  # Gunakan MultinomialNB\n",
    "    naive_bayes_model.fit(X_train_vect, y_train)\n",
    "    predict = naive_bayes_model.predict(X_test_vect)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, predict)\n",
    "    confusion = confusion_matrix(y_test, predict)\n",
    "    print('confusion matrix:\\n', confusion)\n",
    "    classification = classification_report(y_test, predict)\n",
    "    print(classification)\n",
    "    print(\"Accuracy Score:\", round(accuracy, 2))\n",
    "\n",
    "    recall = recall_score(y_test, predict, average='weighted')\n",
    "    print(\"Recall Score:\", recall)\n",
    "    precision = precision_score(y_test, predict, average='weighted')\n",
    "    print(\"Precision Score:\", precision)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    random_num.append(random)\n",
    "    matrix.append(confusion)\n",
    "    report.append(classification)\n",
    "    acc_num.append(accuracy)\n",
    "    re_num.append(recall)\n",
    "    pre_num.append(precision)\n",
    "    test_num.append(test)\n",
    "    print(\"=================================================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bcefe3f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_size</th>\n",
       "      <th>random_state</th>\n",
       "      <th>confusion_matrix</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>42</td>\n",
       "      <td>[[61, 13], [22, 37]]</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.737185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>42</td>\n",
       "      <td>[[117, 34], [40, 74]]</td>\n",
       "      <td>0.720755</td>\n",
       "      <td>0.720755</td>\n",
       "      <td>0.719395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3</td>\n",
       "      <td>42</td>\n",
       "      <td>[[171, 51], [64, 112]]</td>\n",
       "      <td>0.711055</td>\n",
       "      <td>0.711055</td>\n",
       "      <td>0.709731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4</td>\n",
       "      <td>42</td>\n",
       "      <td>[[220, 70], [77, 163]]</td>\n",
       "      <td>0.722642</td>\n",
       "      <td>0.722642</td>\n",
       "      <td>0.722098</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_size  random_state        confusion_matrix  accuracy    recall  \\\n",
       "0        0.1            42    [[61, 13], [22, 37]]  0.736842  0.736842   \n",
       "1        0.2            42   [[117, 34], [40, 74]]  0.720755  0.720755   \n",
       "2        0.3            42  [[171, 51], [64, 112]]  0.711055  0.711055   \n",
       "3        0.4            42  [[220, 70], [77, 163]]  0.722642  0.722642   \n",
       "\n",
       "   precision  \n",
       "0   0.737185  \n",
       "1   0.719395  \n",
       "2   0.709731  \n",
       "3   0.722098  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {'test_size':test_num,\n",
    "        'random_state':random_num,\n",
    "        'confusion_matrix': matrix,\n",
    "        'accuracy': acc_num,\n",
    "        'recall': re_num,\n",
    "        'precision': pre_num}\n",
    "\n",
    "optimal = pd.DataFrame(data)\n",
    "optimal\n",
    "# optimal = optimal.sort_values(by=['accuracy','recall','precision'], ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c59a5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2babfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f90de897",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@ DECISION TREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "50ade7f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test size: 0.1\n",
      "random state: 42\n",
      "Decision Tree Training Score: 1.0\n",
      "Decision Tree Confusion Matrix:\n",
      " [[49 25]\n",
      " [15 44]]\n",
      "Decision Tree Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     negatif       0.77      0.66      0.71        74\n",
      "     positif       0.64      0.75      0.69        59\n",
      "\n",
      "    accuracy                           0.70       133\n",
      "   macro avg       0.70      0.70      0.70       133\n",
      "weighted avg       0.71      0.70      0.70       133\n",
      "\n",
      "Decision Tree Accuracy Score: 0.7\n",
      "Decision Tree Recall Score: 0.6992481203007519\n",
      "Decision Tree Precision Score: 0.708867957938324\n",
      "\n",
      "\n",
      "=================================================================\n",
      "test size: 0.2\n",
      "random state: 42\n",
      "Decision Tree Training Score: 1.0\n",
      "Decision Tree Confusion Matrix:\n",
      " [[96 55]\n",
      " [25 89]]\n",
      "Decision Tree Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     negatif       0.79      0.64      0.71       151\n",
      "     positif       0.62      0.78      0.69       114\n",
      "\n",
      "    accuracy                           0.70       265\n",
      "   macro avg       0.71      0.71      0.70       265\n",
      "weighted avg       0.72      0.70      0.70       265\n",
      "\n",
      "Decision Tree Accuracy Score: 0.7\n",
      "Decision Tree Recall Score: 0.6981132075471698\n",
      "Decision Tree Precision Score: 0.7179622121731899\n",
      "\n",
      "\n",
      "=================================================================\n",
      "test size: 0.3\n",
      "random state: 42\n",
      "Decision Tree Training Score: 1.0\n",
      "Decision Tree Confusion Matrix:\n",
      " [[144  78]\n",
      " [ 44 132]]\n",
      "Decision Tree Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     negatif       0.77      0.65      0.70       222\n",
      "     positif       0.63      0.75      0.68       176\n",
      "\n",
      "    accuracy                           0.69       398\n",
      "   macro avg       0.70      0.70      0.69       398\n",
      "weighted avg       0.71      0.69      0.69       398\n",
      "\n",
      "Decision Tree Accuracy Score: 0.69\n",
      "Decision Tree Recall Score: 0.6934673366834171\n",
      "Decision Tree Precision Score: 0.7052038307036704\n",
      "\n",
      "\n",
      "=================================================================\n",
      "test size: 0.4\n",
      "random state: 42\n",
      "Decision Tree Training Score: 1.0\n",
      "Decision Tree Confusion Matrix:\n",
      " [[175 115]\n",
      " [ 75 165]]\n",
      "Decision Tree Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     negatif       0.70      0.60      0.65       290\n",
      "     positif       0.59      0.69      0.63       240\n",
      "\n",
      "    accuracy                           0.64       530\n",
      "   macro avg       0.64      0.65      0.64       530\n",
      "weighted avg       0.65      0.64      0.64       530\n",
      "\n",
      "Decision Tree Accuracy Score: 0.64\n",
      "Decision Tree Recall Score: 0.6415094339622641\n",
      "Decision Tree Precision Score: 0.6498652291105121\n",
      "\n",
      "\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, recall_score, precision_score\n",
    "\n",
    "random_num_rf = []\n",
    "matrix_rf = []\n",
    "report_rf = []\n",
    "acc_num_rf = []\n",
    "re_num_rf = []\n",
    "pre_num_rf = []\n",
    "test_num_rf = []\n",
    "\n",
    "random_num_dt = []\n",
    "matrix_dt = []\n",
    "report_dt = []\n",
    "acc_num_dt = []\n",
    "re_num_dt = []\n",
    "pre_num_dt = []\n",
    "test_num_dt = []\n",
    "\n",
    "for test in [0.1, 0.2, 0.3, 0.4]:\n",
    "    random = 42\n",
    "    print(\"test size:\", test)\n",
    "    print(\"random state:\", random)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test, random_state=random)\n",
    "    vectorizer = TfidfVectorizer(use_idf=True, smooth_idf=False)\n",
    "    X_train_vect = vectorizer.fit_transform(X_train)\n",
    "    X_test_vect = vectorizer.transform(X_test)\n",
    "    \n",
    "#     # Random Forest\n",
    "#     rf_classifier = RandomForestClassifier()\n",
    "#     rf_classifier.fit(X_train_vect, y_train)\n",
    "#     train_score_rf = rf_classifier.score(X_train_vect, y_train)\n",
    "#     print(\"Random Forest Training Score:\", train_score_rf)\n",
    "#     predict_rf = rf_classifier.predict(X_test_vect)\n",
    "#     accuracy_rf = accuracy_score(y_test, predict_rf)\n",
    "#     confusion_rf = confusion_matrix(y_test, predict_rf)\n",
    "#     print('Random Forest Confusion Matrix:\\n', confusion_rf)\n",
    "#     classification_rf = classification_report(y_test, predict_rf)\n",
    "#     print(\"Random Forest Classification Report:\\n\", classification_rf)\n",
    "#     print(\"Random Forest Accuracy Score:\", round(accuracy_rf, 2))\n",
    "#     recall_rf = recall_score(y_test, predict_rf, average='weighted')\n",
    "#     print(\"Random Forest Recall Score:\", recall_rf)\n",
    "#     precision_rf = precision_score(y_test, predict_rf, average='weighted')\n",
    "#     print(\"Random Forest Precision Score:\", precision_rf)\n",
    "#     print(\"\\n\")\n",
    "#     random_num_rf.append(random)\n",
    "#     matrix_rf.append(confusion_rf)\n",
    "#     report_rf.append(classification_rf)\n",
    "#     acc_num_rf.append(accuracy_rf)\n",
    "#     re_num_rf.append(recall_rf)\n",
    "#     pre_num_rf.append(precision_rf)\n",
    "#     test_num_rf.append(test)\n",
    "#     print(\"=================================================================\")\n",
    "    \n",
    "    # Decision Tree\n",
    "    dt_classifier = DecisionTreeClassifier()\n",
    "    dt_classifier.fit(X_train_vect, y_train)\n",
    "    train_score_dt = dt_classifier.score(X_train_vect, y_train)\n",
    "    print(\"Decision Tree Training Score:\", train_score_dt)\n",
    "    predict_dt = dt_classifier.predict(X_test_vect)\n",
    "    accuracy_dt = accuracy_score(y_test, predict_dt)\n",
    "    confusion_dt = confusion_matrix(y_test, predict_dt)\n",
    "    print('Decision Tree Confusion Matrix:\\n', confusion_dt)\n",
    "    classification_dt = classification_report(y_test, predict_dt)\n",
    "    print(\"Decision Tree Classification Report:\\n\", classification_dt)\n",
    "    print(\"Decision Tree Accuracy Score:\", round(accuracy_dt, 2))\n",
    "    recall_dt = recall_score(y_test, predict_dt, average='weighted')\n",
    "    print(\"Decision Tree Recall Score:\", recall_dt)\n",
    "    precision_dt = precision_score(y_test, predict_dt, average='weighted')\n",
    "    print(\"Decision Tree Precision Score:\", precision_dt)\n",
    "    print(\"\\n\")\n",
    "    random_num_dt.append(random)\n",
    "    matrix_dt.append(confusion_dt)\n",
    "    report_dt.append(classification_dt)\n",
    "    acc_num_dt.append(accuracy_dt)\n",
    "    re_num_dt.append(recall_dt)\n",
    "    pre_num_dt.append(precision_dt)\n",
    "    test_num_dt.append(test)\n",
    "    print(\"=================================================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "39f4dbf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_size</th>\n",
       "      <th>random_state</th>\n",
       "      <th>confusion_matrix</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>42</td>\n",
       "      <td>[[49 25]\\n [15 44]]</td>\n",
       "      <td>0.699248</td>\n",
       "      <td>0.699248</td>\n",
       "      <td>0.708868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>42</td>\n",
       "      <td>[[96 55]\\n [25 89]]</td>\n",
       "      <td>0.698113</td>\n",
       "      <td>0.698113</td>\n",
       "      <td>0.717962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3</td>\n",
       "      <td>42</td>\n",
       "      <td>[[144  78]\\n [ 44 132]]</td>\n",
       "      <td>0.693467</td>\n",
       "      <td>0.693467</td>\n",
       "      <td>0.705204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4</td>\n",
       "      <td>42</td>\n",
       "      <td>[[175 115]\\n [ 75 165]]</td>\n",
       "      <td>0.641509</td>\n",
       "      <td>0.641509</td>\n",
       "      <td>0.649865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_size  random_state         confusion_matrix  accuracy    recall  \\\n",
       "0        0.1            42      [[49 25]\\n [15 44]]  0.699248  0.699248   \n",
       "1        0.2            42      [[96 55]\\n [25 89]]  0.698113  0.698113   \n",
       "2        0.3            42  [[144  78]\\n [ 44 132]]  0.693467  0.693467   \n",
       "3        0.4            42  [[175 115]\\n [ 75 165]]  0.641509  0.641509   \n",
       "\n",
       "   precision  \n",
       "0   0.708868  \n",
       "1   0.717962  \n",
       "2   0.705204  \n",
       "3   0.649865  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_dt = {'test_size': test_num_dt,\n",
    "           'random_state': random_num_dt,\n",
    "           'confusion_matrix': matrix_dt,\n",
    "           'accuracy': acc_num_dt,\n",
    "           'recall': re_num_dt,\n",
    "           'precision': pre_num_dt}\n",
    "\n",
    "optimal_dt = pd.DataFrame(data_dt)\n",
    "\n",
    "# Format confusion matrix, accuracy, recall, dan precision\n",
    "optimal_dt['confusion_matrix'] = optimal_dt['confusion_matrix'].apply(lambda x: str(x))\n",
    "optimal_dt['accuracy'] = optimal_dt['accuracy'].apply(lambda x: round(x, 6))\n",
    "optimal_dt['recall'] = optimal_dt['recall'].apply(lambda x: round(x, 6))\n",
    "optimal_dt['precision'] = optimal_dt['precision'].apply(lambda x: round(x, 6))\n",
    "\n",
    "optimal_dt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb03667d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4fe09b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   test_size  random_state         confusion_matrix  accuracy    recall  \\\n",
      "0        0.1            42      [[58 16]\\n [17 42]]  0.751880  0.751880   \n",
      "1        0.2            42  [[115  36]\\n [ 30  84]]  0.750943  0.750943   \n",
      "2        0.3            42  [[164  58]\\n [ 54 122]]  0.718593  0.718593   \n",
      "3        0.4            42  [[213  77]\\n [ 81 159]]  0.701887  0.701887   \n",
      "\n",
      "   precision  \n",
      "0   0.751510  \n",
      "1   0.753051  \n",
      "2   0.719342  \n",
      "3   0.701504  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, recall_score, precision_score\n",
    "\n",
    "random_num = []\n",
    "matrix = []\n",
    "report = []\n",
    "acc_num = []\n",
    "re_num = []\n",
    "pre_num = []\n",
    "test_num = []\n",
    "\n",
    "for test in [0.1, 0.2, 0.3, 0.4]:\n",
    "    random = 42\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test, random_state=random)\n",
    "    vectorizer = TfidfVectorizer(use_idf=True, smooth_idf=False)\n",
    "    X_train_vect = vectorizer.fit_transform(X_train)\n",
    "    X_test_vect = vectorizer.transform(X_test)\n",
    "    SVM = SVC(kernel='linear')\n",
    "    SVM.fit(X_train_vect, y_train)\n",
    "    train_score = SVM.score(X_train_vect, y_train)\n",
    "    predict = SVM.predict(X_test_vect)\n",
    "    accuracy = accuracy_score(y_test, predict)\n",
    "    confusion = confusion_matrix(y_test, predict)\n",
    "    classification = classification_report(y_test, predict)\n",
    "    recall = recall_score(y_test, predict, average='weighted')\n",
    "    precision = precision_score(y_test, predict, average='weighted')\n",
    "\n",
    "    random_num.append(random)\n",
    "    matrix.append(confusion)\n",
    "    report.append(classification)\n",
    "    acc_num.append(accuracy)\n",
    "    re_num.append(recall)\n",
    "    pre_num.append(precision)\n",
    "    test_num.append(test)\n",
    "\n",
    "data = {'test_size': test_num,\n",
    "        'random_state': random_num,\n",
    "        'confusion_matrix': [str(m) for m in matrix],  # Convert confusion matrices to strings\n",
    "        'accuracy': acc_num,\n",
    "        'recall': re_num,\n",
    "        'precision': pre_num}\n",
    "\n",
    "optimal = pd.DataFrame(data)\n",
    "print(optimal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae20f49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "db9ed6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@ RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b19e3442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test size: 0.1\n",
      "random state: 42\n",
      "Random Forest Training Score: 0.8320738874895046\n",
      "Random Forest Confusion Matrix:\n",
      " [[57 17]\n",
      " [26 33]]\n",
      "Random Forest Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     negatif       0.69      0.77      0.73        74\n",
      "     positif       0.66      0.56      0.61        59\n",
      "\n",
      "    accuracy                           0.68       133\n",
      "   macro avg       0.67      0.66      0.67       133\n",
      "weighted avg       0.67      0.68      0.67       133\n",
      "\n",
      "Random Forest Accuracy Score: 0.68\n",
      "Random Forest Recall Score: 0.6766917293233082\n",
      "Random Forest Precision Score: 0.6748817827701785\n",
      "\n",
      "\n",
      "=================================================================\n",
      "test size: 0.2\n",
      "random state: 42\n",
      "Random Forest Training Score: 0.8479697828139755\n",
      "Random Forest Confusion Matrix:\n",
      " [[113  38]\n",
      " [ 42  72]]\n",
      "Random Forest Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     negatif       0.73      0.75      0.74       151\n",
      "     positif       0.65      0.63      0.64       114\n",
      "\n",
      "    accuracy                           0.70       265\n",
      "   macro avg       0.69      0.69      0.69       265\n",
      "weighted avg       0.70      0.70      0.70       265\n",
      "\n",
      "Random Forest Accuracy Score: 0.7\n",
      "Random Forest Recall Score: 0.6981132075471698\n",
      "Random Forest Precision Score: 0.6969888784374481\n",
      "\n",
      "\n",
      "=================================================================\n",
      "test size: 0.3\n",
      "random state: 42\n",
      "Random Forest Training Score: 0.8509719222462203\n",
      "Random Forest Confusion Matrix:\n",
      " [[160  62]\n",
      " [ 72 104]]\n",
      "Random Forest Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     negatif       0.69      0.72      0.70       222\n",
      "     positif       0.63      0.59      0.61       176\n",
      "\n",
      "    accuracy                           0.66       398\n",
      "   macro avg       0.66      0.66      0.66       398\n",
      "weighted avg       0.66      0.66      0.66       398\n",
      "\n",
      "Random Forest Accuracy Score: 0.66\n",
      "Random Forest Recall Score: 0.6633165829145728\n",
      "Random Forest Precision Score: 0.6617299208965476\n",
      "\n",
      "\n",
      "=================================================================\n",
      "test size: 0.4\n",
      "random state: 42\n",
      "Random Forest Training Score: 0.8526448362720404\n",
      "Random Forest Confusion Matrix:\n",
      " [[208  82]\n",
      " [ 93 147]]\n",
      "Random Forest Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     negatif       0.69      0.72      0.70       290\n",
      "     positif       0.64      0.61      0.63       240\n",
      "\n",
      "    accuracy                           0.67       530\n",
      "   macro avg       0.67      0.66      0.67       530\n",
      "weighted avg       0.67      0.67      0.67       530\n",
      "\n",
      "Random Forest Accuracy Score: 0.67\n",
      "Random Forest Recall Score: 0.6698113207547169\n",
      "Random Forest Precision Score: 0.6687920876745747\n",
      "\n",
      "\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, recall_score, precision_score\n",
    "\n",
    "random_num_rf = []\n",
    "matrix_rf = []\n",
    "report_rf = []\n",
    "acc_num_rf = []\n",
    "re_num_rf = []\n",
    "pre_num_rf = []\n",
    "test_num_rf = []\n",
    "\n",
    "random_num_dt = []\n",
    "matrix_dt = []\n",
    "report_dt = []\n",
    "acc_num_dt = []\n",
    "re_num_dt = []\n",
    "pre_num_dt = []\n",
    "test_num_dt = []\n",
    "\n",
    "for test in [0.1, 0.2, 0.3, 0.4]:\n",
    "    random = 42\n",
    "    print(\"test size:\", test)\n",
    "    print(\"random state:\", random)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test, random_state=random)\n",
    "    vectorizer = TfidfVectorizer(use_idf=True, smooth_idf=False)\n",
    "    X_train_vect = vectorizer.fit_transform(X_train)\n",
    "    X_test_vect = vectorizer.transform(X_test)\n",
    "    \n",
    "    # Random Forest\n",
    "    rf_classifier = RandomForestClassifier(n_estimators=1000, n_jobs=-1, random_state=50, max_leaf_nodes=30)\n",
    "    rf_classifier.fit(X_train_vect, y_train)\n",
    "    train_score_rf = rf_classifier.score(X_train_vect, y_train)\n",
    "    print(\"Random Forest Training Score:\", train_score_rf)\n",
    "    predict_rf = rf_classifier.predict(X_test_vect)\n",
    "    accuracy_rf = accuracy_score(y_test, predict_rf)\n",
    "    confusion_rf = confusion_matrix(y_test, predict_rf)\n",
    "    print('Random Forest Confusion Matrix:\\n', confusion_rf)\n",
    "    classification_rf = classification_report(y_test, predict_rf)\n",
    "    print(\"Random Forest Classification Report:\\n\", classification_rf)\n",
    "    print(\"Random Forest Accuracy Score:\", round(accuracy_rf, 2))\n",
    "    recall_rf = recall_score(y_test, predict_rf, average='weighted')\n",
    "    print(\"Random Forest Recall Score:\", recall_rf)\n",
    "    precision_rf = precision_score(y_test, predict_rf, average='weighted')\n",
    "    print(\"Random Forest Precision Score:\", precision_rf)\n",
    "    print(\"\\n\")\n",
    "    random_num_rf.append(random)\n",
    "    matrix_rf.append(confusion_rf)\n",
    "    report_rf.append(classification_rf)\n",
    "    acc_num_rf.append(accuracy_rf)\n",
    "    re_num_rf.append(recall_rf)\n",
    "    pre_num_rf.append(precision_rf)\n",
    "    test_num_rf.append(test)\n",
    "    print(\"=================================================================\")\n",
    "    \n",
    "#     # Decision Tree\n",
    "#     dt_classifier = DecisionTreeClassifier()\n",
    "#     dt_classifier.fit(X_train_vect, y_train)\n",
    "#     train_score_dt = dt_classifier.score(X_train_vect, y_train)\n",
    "#     print(\"Decision Tree Training Score:\", train_score_dt)\n",
    "#     predict_dt = dt_classifier.predict(X_test_vect)\n",
    "#     accuracy_dt = accuracy_score(y_test, predict_dt)\n",
    "#     confusion_dt = confusion_matrix(y_test, predict_dt)\n",
    "#     print('Decision Tree Confusion Matrix:\\n', confusion_dt)\n",
    "#     classification_dt = classification_report(y_test, predict_dt)\n",
    "#     print(\"Decision Tree Classification Report:\\n\", classification_dt)\n",
    "#     print(\"Decision Tree Accuracy Score:\", round(accuracy_dt, 2))\n",
    "#     recall_dt = recall_score(y_test, predict_dt, average='weighted')\n",
    "#     print(\"Decision Tree Recall Score:\", recall_dt)\n",
    "#     precision_dt = precision_score(y_test, predict_dt, average='weighted')\n",
    "#     print(\"Decision Tree Precision Score:\", precision_dt)\n",
    "#     print(\"\\n\")\n",
    "#     random_num_dt.append(random)\n",
    "#     matrix_dt.append(confusion_dt)\n",
    "#     report_dt.append(classification_dt)\n",
    "#     acc_num_dt.append(accuracy_dt)\n",
    "#     re_num_dt.append(recall_dt)\n",
    "#     pre_num_dt.append(precision_dt)\n",
    "#     test_num_dt.append(test)\n",
    "#     print(\"=================================================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2571f9b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_size</th>\n",
       "      <th>random_state</th>\n",
       "      <th>confusion_matrix</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>42</td>\n",
       "      <td>[[57 17]\\n [26 33]]</td>\n",
       "      <td>0.676692</td>\n",
       "      <td>0.676692</td>\n",
       "      <td>0.674882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>42</td>\n",
       "      <td>[[113  38]\\n [ 42  72]]</td>\n",
       "      <td>0.698113</td>\n",
       "      <td>0.698113</td>\n",
       "      <td>0.696989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3</td>\n",
       "      <td>42</td>\n",
       "      <td>[[160  62]\\n [ 72 104]]</td>\n",
       "      <td>0.663317</td>\n",
       "      <td>0.663317</td>\n",
       "      <td>0.661730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4</td>\n",
       "      <td>42</td>\n",
       "      <td>[[208  82]\\n [ 93 147]]</td>\n",
       "      <td>0.669811</td>\n",
       "      <td>0.669811</td>\n",
       "      <td>0.668792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_size  random_state         confusion_matrix  accuracy    recall  \\\n",
       "0        0.1            42      [[57 17]\\n [26 33]]  0.676692  0.676692   \n",
       "1        0.2            42  [[113  38]\\n [ 42  72]]  0.698113  0.698113   \n",
       "2        0.3            42  [[160  62]\\n [ 72 104]]  0.663317  0.663317   \n",
       "3        0.4            42  [[208  82]\\n [ 93 147]]  0.669811  0.669811   \n",
       "\n",
       "   precision  \n",
       "0   0.674882  \n",
       "1   0.696989  \n",
       "2   0.661730  \n",
       "3   0.668792  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_rf = {'test_size': test_num_rf,\n",
    "           'random_state': random_num_rf,\n",
    "           'confusion_matrix': matrix_rf,\n",
    "           'accuracy': acc_num_rf,\n",
    "           'recall': re_num_rf,\n",
    "           'precision': pre_num_rf}\n",
    "\n",
    "optimal_rf = pd.DataFrame(data_rf)\n",
    "\n",
    "# Format confusion matrix, accuracy, recall, dan precision\n",
    "optimal_rf['confusion_matrix'] = optimal_rf['confusion_matrix'].apply(lambda x: str(x))\n",
    "optimal_rf['accuracy'] = optimal_rf['accuracy'].apply(lambda x: round(x, 6))\n",
    "optimal_rf['recall'] = optimal_rf['recall'].apply(lambda x: round(x, 6))\n",
    "optimal_rf['precision'] = optimal_rf['precision'].apply(lambda x: round(x, 6))\n",
    "\n",
    "optimal_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201d5314",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "230ad2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@GRADIENTBOOSTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4af90381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test size: 0.1\n",
      "random state: 42\n",
      "Gradient Boosting Training Score: 1.0\n",
      "Gradient Boosting Confusion Matrix:\n",
      " [[53 21]\n",
      " [19 40]]\n",
      "Gradient Boosting Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     negatif       0.74      0.72      0.73        74\n",
      "     positif       0.66      0.68      0.67        59\n",
      "\n",
      "    accuracy                           0.70       133\n",
      "   macro avg       0.70      0.70      0.70       133\n",
      "weighted avg       0.70      0.70      0.70       133\n",
      "\n",
      "Gradient Boosting Accuracy Score: 0.7\n",
      "Gradient Boosting Recall Score: 0.6992481203007519\n",
      "Gradient Boosting Precision Score: 0.7004567429502718\n",
      "\n",
      "\n",
      "=================================================================\n",
      "test size: 0.2\n",
      "random state: 42\n",
      "Gradient Boosting Training Score: 1.0\n",
      "Gradient Boosting Confusion Matrix:\n",
      " [[108  43]\n",
      " [ 30  84]]\n",
      "Gradient Boosting Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     negatif       0.78      0.72      0.75       151\n",
      "     positif       0.66      0.74      0.70       114\n",
      "\n",
      "    accuracy                           0.72       265\n",
      "   macro avg       0.72      0.73      0.72       265\n",
      "weighted avg       0.73      0.72      0.73       265\n",
      "\n",
      "Gradient Boosting Accuracy Score: 0.72\n",
      "Gradient Boosting Recall Score: 0.7245283018867924\n",
      "Gradient Boosting Precision Score: 0.7304735390438788\n",
      "\n",
      "\n",
      "=================================================================\n",
      "test size: 0.3\n",
      "random state: 42\n",
      "Gradient Boosting Training Score: 1.0\n",
      "Gradient Boosting Confusion Matrix:\n",
      " [[160  62]\n",
      " [ 58 118]]\n",
      "Gradient Boosting Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     negatif       0.73      0.72      0.73       222\n",
      "     positif       0.66      0.67      0.66       176\n",
      "\n",
      "    accuracy                           0.70       398\n",
      "   macro avg       0.69      0.70      0.70       398\n",
      "weighted avg       0.70      0.70      0.70       398\n",
      "\n",
      "Gradient Boosting Accuracy Score: 0.7\n",
      "Gradient Boosting Recall Score: 0.6984924623115578\n",
      "Gradient Boosting Precision Score: 0.699280295463044\n",
      "\n",
      "\n",
      "=================================================================\n",
      "test size: 0.4\n",
      "random state: 42\n",
      "Gradient Boosting Training Score: 1.0\n",
      "Gradient Boosting Confusion Matrix:\n",
      " [[209  81]\n",
      " [ 93 147]]\n",
      "Gradient Boosting Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     negatif       0.69      0.72      0.71       290\n",
      "     positif       0.64      0.61      0.63       240\n",
      "\n",
      "    accuracy                           0.67       530\n",
      "   macro avg       0.67      0.67      0.67       530\n",
      "weighted avg       0.67      0.67      0.67       530\n",
      "\n",
      "Gradient Boosting Accuracy Score: 0.67\n",
      "Gradient Boosting Recall Score: 0.6716981132075471\n",
      "Gradient Boosting Precision Score: 0.670626804422026\n",
      "\n",
      "\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "random_num_gb = []\n",
    "matrix_gb = []\n",
    "report_gb = []\n",
    "acc_num_gb = []\n",
    "re_num_gb = []\n",
    "pre_num_gb = []\n",
    "test_num_gb = []\n",
    "\n",
    "random_num_xgb = []\n",
    "matrix_xgb = []\n",
    "report_xgb = []\n",
    "acc_num_xgb = []\n",
    "re_num_xgb = []\n",
    "pre_num_xgb = []\n",
    "test_num_xgb = []\n",
    "\n",
    "for test in [0.1, 0.2, 0.3, 0.4]:\n",
    "    random = 42\n",
    "    print(\"test size:\", test)\n",
    "    print(\"random state:\", random)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test, random_state=random)\n",
    "    vectorizer = TfidfVectorizer(use_idf=True, smooth_idf=False)\n",
    "    X_train_vect = vectorizer.fit_transform(X_train)\n",
    "    X_test_vect = vectorizer.transform(X_test)\n",
    "    \n",
    "    # Gradient Boosting\n",
    "    gb_classifier = GradientBoostingClassifier(n_estimators = 400, learning_rate = 0.1, max_depth = 3)\n",
    "    gb_classifier.fit(X_train_vect, y_train)\n",
    "    train_score_gb = gb_classifier.score(X_train_vect, y_train)\n",
    "    print(\"Gradient Boosting Training Score:\", train_score_gb)\n",
    "    predict_gb = gb_classifier.predict(X_test_vect)\n",
    "    accuracy_gb = accuracy_score(y_test, predict_gb)\n",
    "    confusion_gb = confusion_matrix(y_test, predict_gb)\n",
    "    print('Gradient Boosting Confusion Matrix:\\n', confusion_gb)\n",
    "    classification_gb = classification_report(y_test, predict_gb)\n",
    "    print(\"Gradient Boosting Classification Report:\\n\", classification_gb)\n",
    "    print(\"Gradient Boosting Accuracy Score:\", round(accuracy_gb, 2))\n",
    "    recall_gb = recall_score(y_test, predict_gb, average='weighted')\n",
    "    print(\"Gradient Boosting Recall Score:\", recall_gb)\n",
    "    precision_gb = precision_score(y_test, predict_gb, average='weighted')\n",
    "    print(\"Gradient Boosting Precision Score:\", precision_gb)\n",
    "    print(\"\\n\")\n",
    "    random_num_gb.append(random)\n",
    "    matrix_gb.append(confusion_gb)\n",
    "    report_gb.append(classification_gb)\n",
    "    acc_num_gb.append(accuracy_gb)\n",
    "    re_num_gb.append(recall_gb)\n",
    "    pre_num_gb.append(precision_gb)\n",
    "    test_num_gb.append(test)\n",
    "    print(\"=================================================================\")\n",
    "    \n",
    "#     # Extreme Gradient Boosting (XGBoost)\n",
    "#     xgb_classifier = xgb.XGBClassifier()\n",
    "#     xgb_classifier.fit(X_train_vect, y_train)\n",
    "#     train_score_xgb = xgb_classifier.score(X_train_vect, y_train)\n",
    "#     print(\"XGBoost Training Score:\", train_score_xgb)\n",
    "#     predict_xgb = xgb_classifier.predict(X_test_vect)\n",
    "#     accuracy_xgb = accuracy_score(y_test, predict_xgb)\n",
    "#     confusion_xgb = confusion_matrix(y_test, predict_xgb)\n",
    "#     print('XGBoost Confusion Matrix:\\n', confusion_xgb)\n",
    "#     classification_xgb = classification_report(y_test, predict_xgb)\n",
    "#     print(\"XGBoost Classification Report:\\n\", classification_xgb)\n",
    "#     print(\"XGBoost Accuracy Score:\", round(accuracy_xgb, 2))\n",
    "#     recall_xgb = recall_score(y_test, predict_xgb, average='weighted')\n",
    "#     print(\"XGBoost Recall Score:\", recall_xgb)\n",
    "#     precision_xgb = precision_score(y_test, predict_xgb, average='weighted')\n",
    "#     print(\"XGBoost Precision Score:\", precision_xgb)\n",
    "#     print(\"\\n\")\n",
    "#     random_num_xgb.append(random)\n",
    "#     matrix_xgb.append(confusion_xgb)\n",
    "#     report_xgb.append(classification_xgb)\n",
    "#     acc_num_xgb.append(accuracy_xgb)\n",
    "#     re_num_xgb.append(recall_xgb)\n",
    "#     pre_num_xgb.append(precision_xgb)\n",
    "#     test_num_xgb.append(test)\n",
    "#     print(\"=================================================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "14f93395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_size</th>\n",
       "      <th>random_state</th>\n",
       "      <th>confusion_matrix</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>42</td>\n",
       "      <td>[[53 21]\\n [19 40]]</td>\n",
       "      <td>0.699248</td>\n",
       "      <td>0.699248</td>\n",
       "      <td>0.700457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>42</td>\n",
       "      <td>[[108  43]\\n [ 30  84]]</td>\n",
       "      <td>0.724528</td>\n",
       "      <td>0.724528</td>\n",
       "      <td>0.730474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3</td>\n",
       "      <td>42</td>\n",
       "      <td>[[160  62]\\n [ 58 118]]</td>\n",
       "      <td>0.698492</td>\n",
       "      <td>0.698492</td>\n",
       "      <td>0.699280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4</td>\n",
       "      <td>42</td>\n",
       "      <td>[[209  81]\\n [ 93 147]]</td>\n",
       "      <td>0.671698</td>\n",
       "      <td>0.671698</td>\n",
       "      <td>0.670627</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_size  random_state         confusion_matrix  accuracy    recall  \\\n",
       "0        0.1            42      [[53 21]\\n [19 40]]  0.699248  0.699248   \n",
       "1        0.2            42  [[108  43]\\n [ 30  84]]  0.724528  0.724528   \n",
       "2        0.3            42  [[160  62]\\n [ 58 118]]  0.698492  0.698492   \n",
       "3        0.4            42  [[209  81]\\n [ 93 147]]  0.671698  0.671698   \n",
       "\n",
       "   precision  \n",
       "0   0.700457  \n",
       "1   0.730474  \n",
       "2   0.699280  \n",
       "3   0.670627  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_gb = {'test_size': test_num_gb,\n",
    "           'random_state': random_num_gb,\n",
    "           'confusion_matrix': matrix_gb,\n",
    "           'accuracy': acc_num_gb,\n",
    "           'recall': re_num_gb,\n",
    "           'precision': pre_num_gb}\n",
    "\n",
    "optimal_gb = pd.DataFrame(data_gb)\n",
    "\n",
    "# Format confusion matrix, accuracy, recall, dan precision\n",
    "optimal_gb['confusion_matrix'] = optimal_gb['confusion_matrix'].apply(lambda x: str(x))\n",
    "optimal_gb['accuracy'] = optimal_gb['accuracy'].apply(lambda x: round(x, 6))\n",
    "optimal_gb['recall'] = optimal_gb['recall'].apply(lambda x: round(x, 6))\n",
    "optimal_gb['precision'] = optimal_gb['precision'].apply(lambda x: round(x, 6))\n",
    "\n",
    "optimal_gb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bdd336",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b23aa9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f5be2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91eeba37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
